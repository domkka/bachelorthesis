[
  {
    "category": "Open Methodology & Documentation",
    "criteria": [
      {
        "name": "Clear Research Protocol",
        "description": "Are the research questions, hypotheses, and methodology explicitly stated? Is there a step-by-step description of the experimental design?"
      },
      {
        "name": "Detailed README File",
        "description": "Does the paper or supplementary materials include a README explaining how to reproduce the study?"
      }
    ]
  },
  {
    "category": "Data Accessibility & Transparency",
    "criteria": [
      {
        "name": "Open Data",
        "description": "Are the raw or processed datasets publicly available? If data cannot be shared, is there a clear justification (e.g., privacy concerns)?"
      },
      {
        "name": "Data Documentation",
        "description": "Is there a data dictionary or codebook explaining variables, formats, and preprocessing steps? Are data collection methods (e.g., surveys, sensors, LMS logs) fully described?"
      },
      {
        "name": "FAIR Compliance",
        "description": "Is the data Findable (DOI or persistent identifier)? Is it Accessible (open license, no paywalls)? Is it Interoperable (standardized formats like CSV, JSON)? Is it Reusable (clear licensing, metadata)?"
      }
    ]
  },
  {
    "category": "Code & Software Availability",
    "criteria": [
      {
        "name": "Open Source Code",
        "description": "Is the analysis code (Python, R, etc.) shared in a repository (GitHub, GitLab)? Are scripts for data cleaning, analysis, and visualization included?"
      },
      {
        "name": "Version Control & Dependencies",
        "description": "Are software versions (e.g., Python 3.10, TensorFlow 2.12) documented? Is there a requirements.txt, environment.yml, or Dockerfile for reproducibility?"
      },
      {
        "name": "Deterministic Execution",
        "description": "If randomness is involved (e.g., ML training), are random seeds fixed and reported?"
      }
    ]
  },
  {
    "category": "Replicability of Analysis",
    "criteria": [
      {
        "name": "Reproducible Workflow",
        "description": "Can the analysis be rerun with the provided code and data?"
      },
      {
        "name": "Transparent Statistical Methods",
        "description": "Are statistical tests, models, and assumptions clearly described? Are effect sizes, confidence intervals, and p-values reported (not just significance)?"
      },
      {
        "name": "Alternative Implementations Tested",
        "description": "If applicable, does the study test robustness by varying methods (e.g., different ML models)?"
      }
    ]
  },
  {
    "category": "Results & Interpretation",
    "criteria": [
      {
        "name": "Same Conclusions Possible",
        "description": "Can an independent researcher reach similar conclusions using the same data and methods? Are limitations and potential biases discussed?"
      },
      {
        "name": "Negative Results Reported",
        "description": "Are non-significant or contradictory findings included (avoiding publication bias)?"
      }
    ]
  }
]